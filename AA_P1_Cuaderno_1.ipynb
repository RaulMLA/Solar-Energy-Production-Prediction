{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![LogoUC3M](https://www.fundacion.uc3m.es/wp-content/uploads/2018/11/Logo-UC3M-nuevo.png)\n",
        "\n",
        "### Aprendizaje Automático · Grado en Ingeniería Informática · Curso 2022/23\n",
        "---\n",
        "# **Cuaderno 1** - Práctica 1: Predicción de la producción de energía\n",
        "***Grupo Reducido 82 - Grupo de laboratorio 13***\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pi-MaiIDcg-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Carga de datos**\n"
      ],
      "metadata": {
        "id": "ZhN55A3nYDX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para comenzar, importaremos las librerías que necesitamos:\n",
        "\n",
        "+ `linear-tree`: Implementación de los modelos de árboles.\n",
        "+ `statsmodels`: Para los intervalos de confianza.\n"
      ],
      "metadata": {
        "id": "6Q0_UawDiu3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade linear-tree\n",
        "!pip install statsmodels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCk36Clg98Mp",
        "outputId": "9b0ef489-43a6-47ed-e9e1-19b1d7c952bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting linear-tree\n",
            "  Downloading linear_tree-0.3.5-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from linear-tree) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from linear-tree) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from linear-tree) (1.2.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.2->linear-tree) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.2->linear-tree) (3.1.0)\n",
            "Installing collected packages: linear-tree\n",
            "Successfully installed linear-tree-0.3.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (0.13.5)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (1.3.5)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (23.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from statsmodels) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25->statsmodels) (2022.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.2->statsmodels) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez instaladas las bibliotecas necesarias, importamos **Numpy** y **Pandas** ya que los necesitaremos para el desarrollo de la práctica.\n",
        "Destacar que nos referiremos a **Numpy** como *np* y a **Pandas** como *pd* por simplicidad."
      ],
      "metadata": {
        "id": "lejQonv8bVNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "_rQEBPIB-C17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, cargaremos los datos necesarios. Dado que somos el grupo 13, usaremos los dos conjuntos de datos correspondientes.</br></br>\n",
        "Por una parte, tenemos los **datos disponibles**, que nos servirán para entrenar, \n",
        "evaluar y construir el modelo final y por otra parte los **datos de competición** sobre los que usaremos el modelo final para hacer las predicciones correspondientes.</br></br>"
      ],
      "metadata": {
        "id": "j-WhTPVNb05b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos disponibles.\n",
        "disp_df = pd.read_csv(\"disp_st13ns1.txt.bz2\",\n",
        "                      compression=\"bz2\",\n",
        "                      index_col=0)\n",
        "\n",
        "# Datos competición.\n",
        "comp_df = pd.read_csv(\"comp_st13ns1.txt.bz2\",\n",
        "                      compression=\"bz2\",\n",
        "                      index_col=0)\n",
        "\n",
        "# Mostramos la información de cada conjunto de datos.\n",
        "print(f\"El conjunto de datos disponibles tiene {len(disp_df)} instancias.\")\n",
        "print(f\"El conjunto de datos de competición tiene {len(disp_df)} instancias.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HeVvq-ublhz",
        "outputId": "a1988fc5-7991-4d72-d8b3-166341278cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El conjunto de datos disponibles tiene 4380 instancias.\n",
            "El conjunto de datos de competición tiene 4380 instancias.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, separamos la **matriz de atributos** (**X**) y el **vector de la variable de respuesta** *salida* (**y**)."
      ],
      "metadata": {
        "id": "1udUEI81enqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos.\n",
        "X = disp_df.drop('salida', axis=1)\n",
        "\n",
        "# Etiquetas.\n",
        "y = disp_df.salida"
      ],
      "metadata": {
        "id": "OwSjZBG3CQaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Análisis Exploratorio de Datos (EDA)**\n",
        "\n",
        "*   Elemento de lista\n",
        "*   Elemento de lista\n",
        "\n",
        "\n",
        "Antes de comenzar, destacar que dado que los resultados deben ser reproducibles, hemos fijado la **semilla de números aleatorios** en los lugares adecuados. Para ello, hemos seleccionado como semilla el número del grupo de prácticas (*13*).</br></br>\n",
        "Para poder realizar el análisis exploratorio de datos, llevaremos a cabo los siguientes pasos:\n",
        "\n",
        "+ Número de instancias y atributos.\n",
        "+ Tipo de atributos (numéricos o categóricos).\n",
        "+ Missing values.\n",
        "+ Tipo de problema (clasificación o regresión).\n",
        "\n",
        "\n",
        "\n",
        "EDA steps (from T1_SKlearnTrees.ipynb):\n",
        "+ How many instances and attributes there are\n",
        "+ What type of attributes there are (numerical or categorical). This is done to check whether there are categorical features that should be encoded (as dummies / one-hot-encoding)\n",
        "+ What attributes have missing values, and how many\n",
        "+ Whether it is a classification or a regression problem (response variable), and in case of classification, whether the class is imbalanced."
      ],
      "metadata": {
        "id": "zH13876u6V7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Número de instancias y atributos**\n",
        "Los **datos disponibles** cuentan con 75 atributos y la variable de respuesta *salida*. Contiene 12 años de datos considerando una instancia por día y todos los años de 365 días. Por tanto, contamos con un total de **4380 instancias**.</br></br>\n",
        "\n",
        "Los **datos de competición** cuentan con las mismas 75 variables de entrada que los datos disponibles y se trata de un conjunto con 2 años de datos y una instancia por día. En este caso, no se proporciona la variable de respuesta salida, dado que usaremos nuestro modelo final para hacer predicciones sobre estos datos como ya hemos indicado antes. Por tanto, contamos con un total de **733 instancias**.</br></br>\n",
        "\n",
        "A continuación, profundizaremos más en los atributos, su significado y nomenclatura.</br></br>\n",
        "\n",
        "Como podemos ver en la siguiente tabla, contamos con **15 atributos** diferentes, cada uno de ellos con su respectivo nombre (identificador) y con su unidad concreta. Estos atributos corresponden con **variables meteorológicas** diversas.</br></br>\n",
        "\n",
        "| Atributo | Descripción | Unidades |\n",
        "| :- | :- | -: |\n",
        "| `apcp_sfc` | Precipitación acumulada de 3 horas en la superficie. | $\\dfrac{kg}{m^2}$ |\n",
        "| `dlwrf_sfc` | Promedio de flujo radiativo de onda larga hacia abajo en la superficie. | $\\dfrac{W}{m^2}$ |\n",
        "| `dswrf_sfc` | Promedio de flujo radiativo de onda corta hacia abajo en la superficie. | $\\dfrac{W}{m^2}$ |\n",
        "| `pres_msl` | La presión del aire al nivel medio del mar. | $Pa$ |\n",
        "| pwat_eatm\t | Agua precipitable sobre toda la profundidad de la atmósfera. | $\\dfrac{kg}{m^2}$ |\n",
        "| `spfh_2m`\t | Humedad específica a 2 m sobre el suelo. | $\\dfrac{kg}{kg}$ |\n",
        "| `tcdc_eatm`\t | Cobertura total de nubes sobre toda la profundidad de la atmósfera. | $\\%$ |\n",
        "| `tcolc_eatm` | Condensado total integrado en la columna sobre toda la atmósfera. | $\\dfrac{kg}{m^2}$ |\n",
        "| `tmax_2m` | Temperatura máxima en las últimas 3 horas a 2 m sobre el suelo. | $K$ |\n",
        "| `tmin_2m` | Temperatura mínima en las últimas 3 horas a 2 m sobre el suelo. | $K$ |\n",
        "| `tmp_2m` | Temperatura actual a 2 m sobre el suelo.\t| $K$ |\n",
        "| `tmp_sfc` | Temperatura de la superficie. | $K$ |\n",
        "| `ulwrf_sfc` | Radiación ascendente de onda larga en la superficie. | $\\dfrac{kg}{m^2}$ |\n",
        "| `ulwrf_tatm` | Radiación ascendente de onda larga en la parte superior de la atmósfera. | $\\dfrac{kg}{m^2}$ |\n",
        "| `uswrf_sfc` | Radiación ascendente de onda corta en la superficie. | $\\dfrac{kg}{m^2}$ |\n",
        "\n",
        "</br>Partiendo de los 15 atributos que podemos observar en la tabla anterior, se indica una variable en los datos para cada uno ellos en 5 momentos del día. Esto es, contamos con:</br></br>\n",
        "\n",
        "$5\\;instantes\\;de\\;tiempo\\;\\cdot\\;15\\;variables\\;meteorológicas\\;=\\;75\\;variables\\;de\\;entrada$\n",
        "\n",
        "</br>Los instantes de tiempo vienen dados por una numeración del 1 al 5:\n",
        "+ 1 $\\rightarrow$ 12h\n",
        "+ 2 $\\rightarrow$ 15h\n",
        "+ 3 $\\rightarrow$ 18h\n",
        "+ 4 $\\rightarrow$ 21h\n",
        "+ 5 $\\rightarrow$ 24h\n",
        "\n",
        "</br>Por tanto, cada variable meteorológica aparece en el conjunto de datos 5 veces, una por cada instante de tiempo. El instante de tiempo se indica en el subíndice $i$, donde $i=1,2,3,4,5$. Por ejemplo, $apcp\\_sfc_1$ es la variable que indica la precipitación acumulada de 3 horas en la superficie a las 12h (instante de tiempo 1)."
      ],
      "metadata": {
        "id": "ipUSxR_Cr8-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tipo de atributos**.\n",
        "Dentro de los diferentes tipos de atributos de los datos podemos encontrar los categóricos, numéricos u ordinales.</br></br>\n",
        "\n",
        "En el caso de nuestros datos, podemos ver como claramente todos ellos son **atributos numéricos reales** a excepción de la variable de respuesta *salida*, la cual es un **atributo numérico entero**.</br></br>\n",
        "\n",
        "Por tanto, dado que todos los datos con los que vamos a tratar son atributos numéricos, no tendremos que transformar ninguna variable categórica en one-hot-encoding, dado que no vamos a lidiar con ninguna variable de este tipo.\n"
      ],
      "metadata": {
        "id": "-OgKhQTDsCF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos todos los datos.\n",
        "print('Matriz de atributos:\\n\\n', X)\n",
        "print('\\n\\nVector de la variable de respuesta:\\n\\n', y)\n",
        "\n",
        "# Mostramos el tipo de dato de una variable meteorológica y de un valor de la variable de respuesta.\n",
        "print('\\nEjemplo de tipo de dato de variable meteorológica:', type(X['apcp_sf1_1'][0]))\n",
        "print('Ejemplo de tipo de dato de variable de respuesta:', type(y[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SKPmjWDo3Fi",
        "outputId": "6b42097c-4dfc-498a-9451-1000ce9c5264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de atributos:\n",
            "\n",
            "        apcp_sf1_1  apcp_sf2_1  apcp_sf3_1  apcp_sf4_1  apcp_sf5_1  dlwrf_s1_1  \\\n",
            "V1       0.000000    0.000000    0.000000    0.000000    0.000000  276.583582   \n",
            "V2       0.000000    0.000000    0.011818    0.037273    0.543636  249.089505   \n",
            "V3       0.014545    0.000000    0.000000    0.000000    0.002727  229.461820   \n",
            "V4       0.000000    0.009091    0.000000    0.000000    0.000000  239.590321   \n",
            "V5       0.000000    0.000000    0.000000    0.000000    0.000000  230.253657   \n",
            "...           ...         ...         ...         ...         ...         ...   \n",
            "V4376    0.000909    0.114545    0.352727    0.882727    1.379091  284.532288   \n",
            "V4377    0.000909    0.000000    0.000000    0.000000    0.000000  251.460183   \n",
            "V4378    0.000000    0.000000    0.000000    0.000000    0.000000  268.446164   \n",
            "V4379    0.000000    0.000000    0.000000    0.000000    0.000000  268.225686   \n",
            "V4380    0.000000    0.000000    0.000000    0.000000    0.000000  268.385348   \n",
            "\n",
            "       dlwrf_s2_1  dlwrf_s3_1  dlwrf_s4_1  dlwrf_s5_1  ...  ulwrf_t1_1  \\\n",
            "V1     246.514368  251.629031  264.832217  262.468350  ...  201.425894   \n",
            "V2     282.460488  297.254822  315.532651  310.292719  ...  230.836691   \n",
            "V3     215.177840  218.042184  245.620031  246.749223  ...  226.019290   \n",
            "V4     261.169269  271.857217  258.001828  247.076775  ...  235.784869   \n",
            "V5     235.563414  243.941731  266.031791  269.572826  ...  231.005317   \n",
            "...           ...         ...         ...         ...  ...         ...   \n",
            "V4376  277.760515  293.636938  337.863753  330.097956  ...  236.903184   \n",
            "V4377  244.463848  248.985195  266.057689  265.432201  ...  244.682028   \n",
            "V4378  271.475733  274.081410  287.933849  284.624115  ...  239.584692   \n",
            "V4379  263.890245  271.744013  291.337566  291.260448  ...  270.318764   \n",
            "V4380  265.254364  271.679615  291.476737  288.541684  ...  247.253002   \n",
            "\n",
            "       ulwrf_t2_1  ulwrf_t3_1  ulwrf_t4_1  ulwrf_t5_1  uswrf_s1_1  uswrf_s2_1  \\\n",
            "V1     249.504475  251.942089  258.069677  254.249663         0.0    9.181818   \n",
            "V2     200.094627  202.663639  196.833872  202.962007         0.0    4.545455   \n",
            "V3     232.556009  233.298932  211.631876  210.620375         0.0   13.909091   \n",
            "V4     235.189503  236.216754  244.018491  239.049223         0.0    5.454545   \n",
            "V5     230.797569  233.680077  252.037280  246.291591         0.0    9.000000   \n",
            "...           ...         ...         ...         ...         ...         ...   \n",
            "V4376  236.348444  224.870748  175.644218  190.153040         0.0    6.818182   \n",
            "V4377  243.310976  248.244164  263.429332  260.205636         0.0   10.000000   \n",
            "V4378  221.705779  236.372099  273.823583  274.388403         0.0    7.909091   \n",
            "V4379  257.707263  254.163126  281.832139  277.711556         0.0    9.727273   \n",
            "V4380  241.352363  245.428872  257.719322  257.394481         0.0    9.000000   \n",
            "\n",
            "       uswrf_s3_1  uswrf_s4_1  uswrf_s5_1  \n",
            "V1      49.000000  103.000000   68.000000  \n",
            "V2      19.000000   47.272727   32.909091  \n",
            "V3      77.636364  141.090909   90.454545  \n",
            "V4      28.909091   90.818182   62.636364  \n",
            "V5      47.181818  102.272727   67.636364  \n",
            "...           ...         ...         ...  \n",
            "V4376   28.545455   27.181818   18.727273  \n",
            "V4377   50.090909  104.545455   68.454545  \n",
            "V4378   46.909091  102.000000   67.000000  \n",
            "V4379   48.181818  104.909091   68.818182  \n",
            "V4380   47.000000   98.636364   64.818182  \n",
            "\n",
            "[4380 rows x 75 columns]\n",
            "\n",
            "\n",
            "Vector de la variable de respuesta:\n",
            "\n",
            " V1       11119200\n",
            "V2        5530500\n",
            "V3        5596200\n",
            "V4        4360500\n",
            "V5       10572300\n",
            "           ...   \n",
            "V4376     3780900\n",
            "V4377    11463300\n",
            "V4378    11071200\n",
            "V4379    11222700\n",
            "V4380    10770600\n",
            "Name: salida, Length: 4380, dtype: int64\n",
            "\n",
            "Ejemplo de tipo de dato de variable meteorológica: <class 'numpy.float64'>\n",
            "Ejemplo de tipo de dato de variable de respuesta: <class 'numpy.int64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede comprobar en las dos últimas llamadas realizadas, las variables de respuesta utilizan atributos del tipo `numpy.float64`, siendo estos valores **numéricos reales**. Por otra parte, la variable de respuesta *salida* utiliza valores del tipo `numpy.int64`, siendo estos valores **numéricos enteros**.\n"
      ],
      "metadata": {
        "id": "-z3HqPlnqjoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Missing values**.\n",
        "(Investigar esto)"
      ],
      "metadata": {
        "id": "6GB8D-p1sCa6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tipo de problema**.\n",
        "Como hemos podido ver anteriormente mostrando los datos en pantalla, este problema es claramente de **regresión**, dado que tendremos que construir un modelo para realizar **predicción numérica**."
      ],
      "metadata": {
        "id": "bqfWIyBzsCde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **División de datos**\n",
        "Como se puede ver en el código a continuación, dividiremos los datos de acuerdo con el enunciado establecido. Esto es, utilizaremos los **10 primeros años** del conjunto de datos disponibles para **entrenamiento** (*train*) y los **2 últimos años** para **pruebas** (*test*).</br></br>\n",
        "\n",
        "Dado que se nos pide que no desordenemos los datos antes de partir en entrenamiento y test para poder respestar el orden temporal, usaremos el parámetro `shuffle = False` al invocar a la función `train_test_split` de Scikit-learn."
      ],
      "metadata": {
        "id": "0NwFIMyeaHPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Entrenamiento (10 primeros años) y test (2 últimos años).\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=2/12, random_state=13, shuffle=False)\n",
        "\n",
        "# !!! REVISAR !!!\n",
        "# ¿V1 ES EL DATO MÁS ANTIGUO O EL MÁS NUEVO?\n",
        "# !!! REVISAR !!!\n",
        "\n",
        "# Comprobamos que los datos se hayan dividido como queremos.\n",
        "print(X_train.shape, y_train.shape)   # 3650 días -> 10 años.\n",
        "print(X_test.shape, y_test.shape)     # 720 días  ->  2 años.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IotTN2G5wie4",
        "outputId": "ab91486f-99e2-489d-e06d-269e51736f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3650, 75) (3650,)\n",
            "(730, 75) (730,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede ver y, como hemos explicado anteriormente, dado que los resultados deben ser reproducibles, hemos fijado la **semilla de números aleatorios** en los lugares adecuados. Para ello, hemos seleccionado como semilla el número del grupo de prácticas (*13*) mediante `random_state = 13`."
      ],
      "metadata": {
        "id": "_WsZ2IFnsBr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Métodos Básicos**\n",
        "Para los modelos básicos, consideraremos los siguientes **métodos básicos**:\n",
        "+ KNN\n",
        "+ Árboles de regresión\n",
        "+ Regresión lineal\n",
        "\n",
        "Además, destacar que las métricas de evaluación son **RMSE** y **MAE**."
      ],
      "metadata": {
        "id": "PqyFsdsozxrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluación con hiperparámetros por omisión**"
      ],
      "metadata": {
        "id": "PJsdn7b-afU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn import tree\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "oB80LPNTu_e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **KNN** -> Se puede normalizar con lo visto en clase. Si normalizamos la salida hay que desnormalizar la salida a la hora de calcular los erroes."
      ],
      "metadata": {
        "id": "8OwRm_keuGun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = KNeighborsRegressor()\n",
        "np.random.seed(13)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "#Calculo del error cuadrático medio\n",
        "rmse_knn = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "print(f\"Error cuadrático medio del modelo KNN: {rmse_knn}\")\n",
        "\n",
        "#Calculo del error absoluto medio\n",
        "mae_knn = metrics.mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Error absoluto medio del modelo KNN: {mae_knn}\")\n",
        "np.random.seed(13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8k2OjR9vPNM",
        "outputId": "cd32fbf6-79d2-4ac5-9020-2c0306e29ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error cuadrático medio del modelo KNN: 4020440.2520662835\n",
            "Error absoluto medio del modelo KNN: 2841221.0750684934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Árboles de regresión**"
      ],
      "metadata": {
        "id": "xUC_HhekuG2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = tree.DecisionTreeRegressor()\n",
        "np.random.seed(13)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "RWgfQevGzwcK",
        "outputId": "68e0a0b4-2196-4b83-9492-d5fff740224e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones del conjunto de test.\n",
        "y_pred = clf.predict(X_test)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyRZeZmIVjpG",
        "outputId": "1b33236f-4a4d-4043-f3f7-814f80f0c993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12360600.  2887500.  1863000.  8627100. 12051300. 10780200. 12257700.\n",
            " 12018300. 10506900.  9209700. 11947800. 10650900. 11787000.  9634200.\n",
            "  2383200. 12424800.  9751500.  1292700.  1556700.  7822500. 13579800.\n",
            " 10182600. 12569400.  7721700. 12569400.  7462200. 10155300.  1326000.\n",
            " 13276500. 14262000.  8058000. 11182500.  3078900.  2880900. 13791300.\n",
            " 10691100.   826500.  3493800. 12941100. 10553100. 15685800.  7054500.\n",
            " 16043700.  3833100. 15738000. 10012800. 18220800.  7948800.  5030400.\n",
            " 14645100. 16559100. 12187500. 16347300. 16742100. 10691100.  7390200.\n",
            " 16841700. 12315900. 20532000.  7942500. 14077500.  6570900. 19781400.\n",
            " 15477600.  1766100.  1806000. 19781400. 20868300. 20943300. 17886900.\n",
            " 20987100. 19540200. 20454900. 18595200. 11079000. 20454900.  8562000.\n",
            " 15089700.  7687200. 20190300. 17816700. 18488400. 15746400. 19740000.\n",
            " 20507700.  8528700.  5618100.  8433900.  2047200. 21092400. 10354688.\n",
            " 24992700. 20541300. 21474300. 23115300. 24992700. 10354688. 20161800.\n",
            " 17978400. 19530900. 25209000.   951300.  2397900. 25425600. 14523000.\n",
            " 17085900. 27333000. 25641600. 24520200. 24885900.  3843900. 11391600.\n",
            " 17816700. 12142200.  5397300.  3650100.  5397300. 26890500. 27928500.\n",
            " 27523500. 21901500.  7586400.  3650100. 11449500. 27635700. 28482000.\n",
            " 27007200. 26532300. 28271700. 28576800. 19649400. 22812300. 25092600.\n",
            " 18767100.  8309100. 25189800. 17472300. 30830100. 28179300. 27592800.\n",
            " 11343900. 19731900. 26400000. 28254900. 23334300. 20765400. 17625600.\n",
            " 17700600. 15279900. 11165100. 26826000. 15076800. 17842200. 29175000.\n",
            " 24948000. 23512800. 29448000. 29586900. 10158600. 27886800. 25965900.\n",
            " 18764400. 11298300. 13120500. 19335600. 25189800. 18067800. 28254900.\n",
            " 29222400. 16309500. 27023700. 24102600. 22564500. 24203400. 12069300.\n",
            " 11449500. 29179500. 30343800. 19799100. 14794800. 16653900. 10617900.\n",
            " 16374300. 17700600. 23307600. 18058800. 27353100. 21852600. 20651100.\n",
            "  6305400. 28217400. 28327200. 28271700. 28271700. 26771700. 25904700.\n",
            " 28568700. 27985200. 29583900. 18079800. 28055400. 28536900. 28271700.\n",
            " 25749900. 28182900. 18938400. 19283400. 25291500.  6438000. 26937600.\n",
            " 29179500. 10354688.  6357900. 12859800. 26212800. 26212800. 19283400.\n",
            " 24732000. 15819000. 24927300. 27093600. 26411100. 24810000. 26641800.\n",
            " 25807800. 16141800. 27093600. 24885000. 25575000. 17707200. 25983600.\n",
            " 25779900. 25888500. 12112200. 22518600. 25807800. 25692600. 25540200.\n",
            " 19904400. 10461000. 23523600. 19247400. 15405300. 25163100. 23934600.\n",
            " 14480400. 20507700. 23043900. 18955500. 19877700. 22307700. 19463100.\n",
            " 25688400. 25163100. 23934600. 25688400. 19687200. 20937000. 20749200.\n",
            " 20885100. 21149400. 19031100. 20886900. 16707300. 22318800. 19091100.\n",
            " 17661000. 20868300.  5726100. 21222600. 20348100. 20348100. 12051000.\n",
            " 13363800. 16364700. 15541200.  9626400. 20580300. 19842300. 18280800.\n",
            " 17811000.  6867300.  9342300.  9048300. 13821900.  2063700.  7856400.\n",
            "  2832000. 18657000.  8422800. 16162800. 16221600. 10227000. 17653500.\n",
            "  9204300.  8840100.  4189200.  2176800. 11469300. 16375500.  4442100.\n",
            "  3565800.  7214100.  7214100. 17816700. 13922400.  3399900.  7751700.\n",
            "  3588000.  1292700. 15213600. 13754400. 13409700.  6096000.  9370800.\n",
            "  5435700.  3050100.  2280900.  4740000. 12153300.  2647500.  1662300.\n",
            "  2397900.  8430600.  3895800.  2371500.  9370800.  1556700.  1768500.\n",
            "  2280900. 10780200. 12321900.  2062800. 13415700.  5530500.  1292700.\n",
            "  8190300. 12809100. 12178200. 11595600. 12079200.  1233300.  1691100.\n",
            "  7984200.  8052600.  5337300.  6725100. 11354100.  5337300. 11166000.\n",
            " 12255600. 11070900.  5351700. 11351100. 10009500. 10266600. 11594100.\n",
            "  9493800.  2184600.  5605800. 12400800. 11429700. 11020500.  8857500.\n",
            "  2345100.  6948000.  6278700. 10281600.  5069700.  4380300.  2985900.\n",
            "  1603200.  2184600. 12018300. 11243100. 10399500. 10821900.  1024800.\n",
            "  1727100.  3636300. 12563700.  3621900. 12057000. 11785800. 12057000.\n",
            " 13718400.  4740000. 13023900.  7177200. 14574600. 13579800. 12569400.\n",
            " 13696500. 13978800.  2708700.  1131000. 11182500.  7604700.  1872600.\n",
            "  1885800.  1210800. 14929800. 14306400. 13109400.  1292700.  5891700.\n",
            "  3941400. 16053300. 16936500. 11170800.  2880900. 12719700. 16572000.\n",
            " 12187500.  1667100. 10902000. 14430900.  1341300. 15121800. 15121800.\n",
            " 13893300.  3227400. 17927400. 15323100. 14153400.  3423300.  8063100.\n",
            " 20107500. 19781400. 13250700. 15997800. 10354688. 16587600.  9327900.\n",
            " 15477600.  5814600. 19781400. 20987100. 20543400. 21199500. 21591000.\n",
            "  4390500. 20454900. 21591300. 20342700. 22242600.  7687200. 10354688.\n",
            " 13096800. 20655300. 15195000. 20448900.  7480800. 12315900. 22351200.\n",
            " 18389100. 22200900. 15360300. 20146500. 25784100. 17112600. 22700100.\n",
            "  4730100. 16395900. 10354688. 17923500. 18462900. 13816200. 13846200.\n",
            " 22863000. 25523400. 24527700. 20454000. 26130000. 14480400.  8820000.\n",
            "  9626400. 17816700.  9626400. 26336700. 27669300. 12443100. 16395900.\n",
            " 25421400. 26684400. 10336200.  9819600. 26357400. 17978400. 22671600.\n",
            " 26768700. 24760200. 17978400. 22911900. 16261800. 11215200. 18554100.\n",
            " 18767100. 23493300. 19427700.  6086400. 26852700. 29448000. 28898100.\n",
            " 28898100. 20231100. 14083500. 28490100. 26400000. 22481700. 10354688.\n",
            " 28055400. 24757200. 19408500.  5397300. 26662200. 18782100. 26826000.\n",
            " 10336200. 15031200. 28179300.  6086400. 26058000. 25227600. 26400000.\n",
            " 24117000. 19374000. 29074500. 28382100. 28233300. 25957500. 25012500.\n",
            " 29370300. 26034000. 12885600. 16703400. 29580900. 28536900. 30838500.\n",
            " 29633400. 30066900. 29331000. 29331000. 30066900. 28254900. 28665900.\n",
            " 29398200. 26034000. 27985200. 26187900. 24117000. 29263500.  6086400.\n",
            " 26095800. 29288100. 29344200. 27360300. 24117000. 27131100. 28182900.\n",
            " 23304600. 14257800. 22485000. 23065200. 27618900. 26105700. 25893300.\n",
            " 21694500. 27852900. 28001100. 27846900. 27852900. 26935800.  6305400.\n",
            " 23760900. 17472300. 30389700. 29792400. 26758800. 26641800. 21149700.\n",
            " 24752100. 26424600. 26435700. 24545700. 22485000. 25842600. 20008800.\n",
            " 25910100. 26219700. 24506100. 25020600. 13754400.  9626400. 13869000.\n",
            " 28122000. 26746200. 24506100. 24644100. 26746200. 23194800. 23307600.\n",
            " 26746200. 26746200. 24722100. 19904400. 25540200. 21777300. 24832200.\n",
            " 25163100. 25200900. 23877900. 23043900. 21252600. 20507700. 22069800.\n",
            " 20338500. 13764000. 20396100. 21354900. 22689600. 21149400. 10866900.\n",
            " 18727200. 21149400. 15098400. 21890400. 21595800. 15716100. 21434100.\n",
            " 20004000. 19114800. 12793200. 20004000. 11165100. 21174900. 18282300.\n",
            " 20868300. 21231900. 12957300.   951300.  5647800. 19335600. 13977000.\n",
            " 17907900. 15551400. 17927400. 14454900. 18160500. 18377700. 16110300.\n",
            " 14936400. 17362500. 16986000. 17659200. 15541200. 17655600. 16719000.\n",
            " 16422900.  7134900.  3856200. 15387300.  9370800.  6393300.  7935300.\n",
            " 16587000. 10227000. 15478500. 15478500. 15478500.  3683400.  3636300.\n",
            " 15478500. 15510300.  6874200.  4271400. 14201400. 15213600.  7177200.\n",
            " 10110600.  2357700. 12979800.  6096000.  9529200.  9472800.  9552000.\n",
            " 10780200. 13302900. 11180100. 12724500.  3621900.  3487500. 12735900.\n",
            " 11973900. 12698700.  8752800. 12522600.  9819600.  7329300.  3459900.\n",
            "  8137500. 10650900. 11662800. 11662800.  1942800. 11596800. 11820600.\n",
            " 11631300. 11238000. 11980200. 11804100. 11429700. 11020500.  8189700.\n",
            "  3144600. 11234700. 11725200.  9751500.  3245400.  8461800.  8429400.\n",
            "  5351700. 10650900.  4230900.  8440200.  2677500.  7984200. 11119200.\n",
            "  4230900. 11517900.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparación de predicciones actuales con \n",
        "print(np.hstack((y_pred[:5,np.newaxis], y_test[:5,np.newaxis])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I0ODVPPWtws",
        "outputId": "878f0754-44e7-4748-835b-77e4181f496d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10959060. 11121600.]\n",
            " [10084440. 10962000.]\n",
            " [ 1877820.  1597200.]\n",
            " [10930080. 11056200.]\n",
            " [ 8185740.  8856600.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-2f31e14bb28e>:2: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  print(np.hstack((y_pred[:5,np.newaxis], y_test[:5,np.newaxis])))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "rmse_tree = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "print(f\"RMSE del árbol: {rmse_tree}\")\n",
        "\n",
        "#Probamos si es mejor que un dummy regressor tree\n",
        "\n",
        "regr_mean = DummyRegressor(strategy=\"mean\")\n",
        "regr_mean.fit(X_train, y_train)\n",
        "rmse_mean = np.sqrt(metrics.mean_squared_error(y_test, regr_mean.predict(X_test)))\n",
        "\n",
        "print(f\"RMSE del arbol dummy (mean): {rmse_mean}\")\n",
        "print(f\"RMSE ratio tree/dummy(mean): {rmse_tree/rmse_mean}\")\n",
        "\n",
        "\n",
        "mae_tree = metrics.mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "regr_median = DummyRegressor(strategy=\"median\")\n",
        "regr_median.fit(X_train, y_train)\n",
        "mae_median = metrics.mean_absolute_error(y_test, regr_median.predict(X_test))\n",
        "\n",
        "print(f\"MAE of the tree: {mae_tree}\")\n",
        "print(f\"MAE of dummy (median): {mae_median}\")\n",
        "print(f\"MAE ratio tree/dummy(median): {mae_tree/mae_median}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjgB_hIxXJ9d",
        "outputId": "5e56c70e-bc9e-434c-97f2-e413512ebf28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE del árbol: 4020440.2520662835\n",
            "RMSE del arbol dummy (mean): 7678668.504109763\n",
            "RMSE ratio tree/dummy(mean): 0.5235855994974221\n",
            "MAE of the tree: 2841221.0750684934\n",
            "MAE of dummy (median): 6505989.04109589\n",
            "MAE ratio tree/dummy(median): 0.4367085553205772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Regresión lineal**"
      ],
      "metadata": {
        "id": "j2llvQO5uG8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`### **Validación Cruzada** (Usar PredefineSplit(test_fold), alomejor va en ajustes de hiperparametros pero creo que no) "
      ],
      "metadata": {
        "id": "aOix7GcdSPGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ajuste de hiperparámetros**"
      ],
      "metadata": {
        "id": "u5nVrwbHafhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **KNN**"
      ],
      "metadata": {
        "id": "IujsylHruSG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Árboles de regresión**"
      ],
      "metadata": {
        "id": "ppDE4xq_uSOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Regresión lineal**"
      ],
      "metadata": {
        "id": "KQ7KmWRGuSSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusiones**\n",
        "Responder a:\n",
        "+ ¿Cuál es el mejor método?\n",
        "+ ¿Cuál de los métodos\n",
        "básicos de aprendizaje automático es más rápido?\n",
        "+ ¿Los resultados son mejores que los\n",
        "regresores triviales/naive/baseline?\n",
        "+ ¿El ajuste de hiperparámetros mejora con respecto a los\n",
        "valores por omisión?\n",
        "+ ¿Hay algún equilibrio entre tiempo de ejecución y mejora de\n",
        "resultados? "
      ],
      "metadata": {
        "id": "3YrrMZOKafpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reducción de dimensionalidad**"
      ],
      "metadata": {
        "id": "7E_ZIcmCaf0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Métodos avanzados**"
      ],
      "metadata": {
        "id": "dJybkag3awk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluación con hiperparámetros por omisión**"
      ],
      "metadata": {
        "id": "J3J9m3xRawrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SVMs**"
      ],
      "metadata": {
        "id": "KtcdfZq1umnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Random Forests**"
      ],
      "metadata": {
        "id": "LXoWeNWLumu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ajuste de hiperparámetros**"
      ],
      "metadata": {
        "id": "zjjiv7Alawu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SVMs**"
      ],
      "metadata": {
        "id": "KiR0j5pRutBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Random Forests**"
      ],
      "metadata": {
        "id": "r9XoAGbuutIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Interpretación de la importancia de los atributos**"
      ],
      "metadata": {
        "id": "g1LABlYSa4la"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusiones**"
      ],
      "metadata": {
        "id": "ojFrXFYOaw1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos ver en el resultado anterior, la precisión (accuracy) del árbol creado es 0.0, por lo que es nula. Por tanto, se puede ver como el primer modelo claramente no es adecuado para nuestros datos. De esta forma, tendremos que estudiar otro tipo de modelo."
      ],
      "metadata": {
        "id": "rZ9UhRtZXbf5"
      }
    }
  ]
}